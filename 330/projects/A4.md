# C330 A4

## Peter Dulworth

#### Note

The tasks should be run in order because each one depends on imports / variables in the previous one. I have attached the complete python file  as `knn.py` in the same directory that this file lives in if that makes things easier.

I have uploaded an HTML version of this file to http://peterdulworth.com/comp330/A4/. It is identical to this PDF except it has no page breaks so it will be much easier to view. The `html` file is also included in the zip if you prefer it locally.

### Task 1

**Code**

```python
import re
import numpy as np
from collections import defaultdict

# load up all of the 19997 documents in the corpus
corpus = sc.textFile ("s3://chrisjermainebucket/comp330_A6/20_news_same_line.txt")

# each entry in validLines will be a line from the text file
validLines = corpus.filter(lambda x : 'id' in x)

# now we transform it into a bunch of (docID, text) pairs
keyAndText = validLines.map(lambda x : (x[x.index('id="') + 4 : x.index('" url=')], x[x.index('">') + 2:]))

# now we split the text in each (docID, text) pair into a list of words
# after this, we have a data set with (docID, ["word1", "word2", "word3", ...])
# we have a bit of fancy regular expression stuff here to make sure that we do not
# die on some of the documents
regex = re.compile('[^a-zA-Z]')
keyAndListOfWords = keyAndText.map(lambda x : (str(x[0]), regex.sub(' ', x[1]).lower().split()))

# now get the top 20,000 words... first change (docID, ["word1", "word2", "word3", ...])
# to ("word1", 1) ("word2", 1)...
allWords = keyAndListOfWords.flatMap(lambda x: ((j, 1) for j in x[1]))

# now, count all of the words, giving us ("word1", 1433), ("word2", 3423423), etc.
allCounts = allWords.reduceByKey(lambda a, b: a + b)

# and get the top 20,000 words in a local array
# each entry is a ("word1", count) pair -- sorted first by count then by word
topWords = allCounts.takeOrdered(20000, lambda x : (-x[1], x[0]))

# and we'll create a RDD that has a bunch of (word, dictNum) pairs
# start by creating an RDD that has the number 0 thru 20000
# 20000 is the number of words that will be in our dictionary
twentyK = sc.parallelize(range(20000))

# now, we transform (0), (1), (2), ... to ("mostcommonword", 1) ("nextmostcommon", 2), ...
# the number will be the spot in the dictionary used to tell us where the word is located
# HINT: make use of topWords in the lambda that you supply
# since topWords is sorted, we just rank 0 corresponds to topWords[0] etc...
# 0 -> topWords[0] -> ("the", 255140)
dictionary = twentyK.map(lambda rank: (rank, topWords[rank][0]))

# finally, print out some of the dictionary, just for debugging
dictionary.top(10)
# dictionary.takeSample(False, 10)
# dictionary.lookup("the") -> [255140]

################################## TASK 1 #####################################

# flip the dictionary from (rank, word) to (word, rank) so we can join it 
# with the next thing we create
wordToRank = dictionary.map(lambda x: (x[1], x[0]))

# get a master list of (word, docID) pairs where each word in each document
# is corresponds to a (word, docID) pair.
allWordsAndDocIDs = keyAndListOfWords.flatMap(lambda x: ((j, x[0]) for j in x[1]))

# take the master list of all the words we just created and join the wordToRank
# dict onto it so that we get (word, (docID, rank)) pairs
# this effectively the rank of the word to the master list
wordToDocAndRank = allWordsAndDocIDs.join(wordToRank)

"""
Algorithm Idea:
start -> (word, (ID, rank))
map -> ((ID, word, rank), 1)
reduceByKey -> ((ID, word, rank), numOccurencesInDocWithID) should now be 1 of these for each word in each document
map -> (ID, (word, rank, numOccurencesInDocWithID))
groupByKey -> (ID, [(word1, rank1, numOccurencesInDocWithID1), (word2, rank2, numOccurencesInDocWithID2), ...])
-> sort array by rank interpolate with zeros?

B <- new array [20,000]
for each thing in array
	B[rank1] = numOccurencesInDocWithID = thing[2]

"""

# helper function that takes a pyspark iterable and converts it to a numpy array
def iterableToArray(iter):
	a = np.zeros(20000)
	# for each (word, rank, numOccurences) tuple
	for wro_tup in iter:
		rank = wro_tup[1]
		a[rank] = wro_tup[2]
	return a

# map -> ((ID, word, rank), 1)
m1 = wordToDocAndRank.map(lambda x: ((x[1][0], x[0], x[1][1]), 1))
# reduceByKey -> ((ID, word, rank), numOccurencesInDocWithID) should now be 1 of these for each word in each document
r1 = m1.reduceByKey(lambda a, b: a + b)
# map -> (ID, (word, rank, numOccurencesInDocWithID))
m2 = r1.map(lambda x: (x[0][0], (x[0][1], x[0][2], x[1])))
# groupByKey -> (ID, [(word1, rank1, numOccurencesInDocWithID1), (word2, rank2, numOccurencesInDocWithID2), ...])
g = m2.groupByKey()
# get result
task1Result = g.map(lambda x: (x[0], iterableToArray(x[1])))
task1Result.cache()

# get results
t1_result1 = task1Result.lookup("20_newsgroups/comp.graphics/37261")[0]
t1_result2 = task1Result.lookup("20_newsgroups/sci.med/58763")[0]
t1_result3 = task1Result.lookup("20_newsgroups/talk.politics.mideast/75944")[0]

# print results
print(t1_result1[t1_result1.nonzero()])
print(t1_result2[t1_result2.nonzero()])
print(t1_result3[t1_result3.nonzero()])
```

**Results** 

```
"20_newsgroups/comp.graphics/37261"
>>> print(t1_result1[t1_result1.nonzero()]) 
[ 8.  2.  6.  3. 12.  4.  3.  6.  2.  1.  1.  5.  2.  2.  2.  3.  1.  1.
  1.  1.  3.  1.  1.  2.  3.  4.  1.  1.  1.  1.  1.  3.  1.  1.  1.  2.
  1.  1.  1.  2.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.
  2.  2.  1.  2.  1.  1.  1.  3.  4.  1.  1.  1.  1.  2.  1.  1.  1.  1.
  1.  1.  1.  1.  2.  1.  1.  1.  1.  5.  2.  2.  1.  1.  5.  1.  4.  1.
  1.  1.  2.  1.  2.  1. 11.  1.  1.  1.  1.  2.  2.  2.  5.  1.  2.  1.
  1.  1.  2.  1.  2.  1.  2.  4.  1.  1.  1.  5.  1.  1.  1.  1.  2.  4.
  1.  1.  1.  3.  1.  1.  1.  1.  3.  2.  2.  1.  1.  6.  1.  6.  1.  1.
  3.  1.  1.  2.  1.  1.  1.  1.  2.  7.  1.  1.  1.  1.  1.]
  
"20_newsgroups/sci.med/58763"
>>> print(t1_result2[t1_result2.nonzero()])
[4. 4. 3. 2. 1. 1. 4. 3. 1. 2. 1. 5. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1.
 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 5. 1. 1. 1. 1. 1.
 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 1. 1.]
 
"20_newsgroups/talk.politics.mideast/75944"
>>> print(t1_result3[t1_result3.nonzero()])
[135.  37.  71.  28.  49.  19.  46.  16.  13.  22.   9.  22.  11.   7.
   7.   6.   4.   6.  12.  11.  10.   3.  10.   4.   2.  21.   5.   4.
   2.   2.   1.   1.   1.   5.   1.  23.   5.   2.   1.   6.   8.   4.
   7.   3.   3.   2.   1.   1.   6.   4.   4.   7.   1.   8.   7.  13.
   4.   4.  10.   3.   3.   2.   2.   3.   7.   4.   1.   2.   4.   8.
   4.   7.   2.   1.   1.   2.   1.   2.   2.   1.   5.   3.   3.   3.
   1.   1.   1.   2.   1.   4.   3.   1.   3.   3.   4.   7.   1.   2.
   1.   3.   2.   1.   4.   6.   3.  11.   1.   6.   3.   1.   3.   1.
   2.   1.   1.   1.   3.   3.   2.   5.   2.   2.   2.   2.   1.   1.
   1.   1.   1.   3.   1.   1.   1.   1.   3.   3.   4.   1.   1.   5.
   1.   1.   2.   6.   2.   2.   1.   1.   1.   1.   1.   1.   3.   5.
   1.   1.   1.   1.   2.   1.   1.   1.   6.   1.   1.   2.   1.   3.
   2.   1.   1.   3.   2.   2.   3.   8.   1.   1.   1.   1.   2.   3.
   1.   2.   6.   1.   1.   2.   1.  13.   4.   1.   1.   1.   1.   1.
   3.   1.   1.   2.   2.   1.   1.   2.   1.   1.   1.   1.   1.   3.
   1.   2.   4.  26.   1.   1.   3.   2.   2.   1.   3.   1.   1.   1.
   1.   1.   1.   1.   1.   2.   6.   1.   1.   1.   6.   1.   1.   1.
   4.   2.   1.   1.   1.   1.   4.   1.   1.   1.   1.   1.   1.   1.
   1.   3.   4.   4.   4.   3.   1.   3.   1.   1.   1.   1.   1.   1.
   4.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   2.
   1.   1.   2.   1.   9.   1.   1.   2.   1.   1.   1.   5.   1.   1.
   2.   1.   1.   2.   1.   1.   1.   1.   6.   1.   1.   1.   1.   1.
   3.   1.   2.   1.   1.   1.   2.   1.   2.   9.   1.   1.   1.   2.
   1.   1.   2.   2.   2.   2.   1.   1.   4.   1.   1.   1.   2.   1.
   1.   1.   1.  11.   2.   1.   1.   1.   1.   1.   1.   1.   2.   1.
   1.   1.   1.   1.   1.   2.   9.   1.   2.   7.   3.   3.   2.   1.
   1.   2.   1.   1.   1.   2.   1.   2.   1.   1.   3.   8.   1.   1.
   1.   1.   1.   8.   1.   1.   1.   2.   1.   1.   1.   1.   1.   1.
   1.   1.   1.   1.   1.  10.   1.   1.   1.   2.   1.   2.   3.   4.
   1.   1.   1.   1.   1.   1.   1.   3.   1.   1.   1.   1.   1.   1.
   8.   1.   1.   1.   1.   1.   1.   1.   6.   1.   1.   1.   1.   1.
   1.   1.   1.   2.   1.   1.   1.   1.   1.   1.  11.   2.   1.   1.
   1.   1.   1.   2.   1.   1.   3.   3.   1.   1.   1.   1.   1.   1.
   1.   1.   1.   2.   1.   1.   1.   3.   1.   1.   1.   1.   1.   1.
   1.   1.   1.   1.   2.   1.   1.   4.   2.   3.   1.   1.   1.   4.
   1.   1.   4.   1.   1.   1.   2.   4.   1.   1.   1.   1.   2.   3.
   1.   1.   1.   2.   1.   1.   2.   1.   1.   1.   1.   1.   1.   1.
   1.   1.   2.   1.   1.   1.   1.   1.   2.   1.   2.   1.   2.   2.
   1.   1.   1.   1.   1.   4.   1.   1.   1.   1.   8.   2.   1.   1.
   1.   1.   2.   3.   1.   1.   1.   1.   1.   3.   1.   1.   1.   1.
   1.   4.   1.   1.   1.   3.   2.   1.   1.   1.   2.   1.   1.   1.
   1.   1.   2.   1.   1.   1.   1.   1.   1.   1.   1.   1.   2.   1.
   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   2.   1.   1.
   1.   1.   1.   4.   2.   3.   2.   1.   1.   1.]
```

### Task 2

**Code**

```python
################################## TASK 2 #####################################

# give our result from task 1 a better name
docToCountVector = task1Result

# docToCountVector is esentially a matrix where each row is the count vector of a doc
# divide each row of the matrix by the number of words in the document that the row corresponds to
tf = docToCountVector.map(lambda x: (x[0], x[1] / x[1].sum()))

# calculate the IDF vector
numDocs = corpus.count() # the number of documents in the corpus
# clip all non-zero values to 1
c1 = docToCountVector.map(lambda x: (x[0], np.clip(x[1], 0, 1)))
# map every row in the matrix to same key
c2 = c1.map(lambda x: ("numDocsVector", x[1])) 
# the ith entry of this vector is the number of documents that contain word i
numDocsWithWord = c2.reduceByKey(lambda a, b: a + b) # sum all of the vectors effectively summing along the columns
numDocsWithWord.cache()

# compute the IDF vector
idf = np.log(numDocs / numDocsWithWord.lookup("numDocsVector")[0])

# compute the TF-IDF vector for each document
task2Result = tf.map(lambda x: (x[0], x[1] * idf))
task2Result.cache()

# get results
t2_result1 = task2Result.lookup("20_newsgroups/comp.graphics/37261")[0]
t2_result2 = task2Result.lookup("20_newsgroups/sci.med/58763")[0]
t2_result3 = task2Result.lookup("20_newsgroups/talk.politics.mideast/75944")[0]

# print results
print(t2_result1[t2_result1.nonzero()])
print(t2_result2[t2_result2.nonzero()])
print(t2_result3[t2_result3.nonzero()])
```

**Results**

```
"20_newsgroups/comp.graphics/37261"
>>> print(t2_result1[t2_result1.nonzero()])
[1.92555059e-03 8.50478606e-04 3.65947527e-03 1.27515309e-03
 7.26881462e-03 2.19975741e-03 2.66216132e-03 6.35871363e-03
 3.43014584e-03 1.65693809e-03 9.44999233e-03 3.95217425e-03
 4.19787791e-03 5.18781198e-03 6.54906258e-03 9.61804463e-06
 9.42766276e-03 2.87951994e-03 5.38035007e-04 6.14710796e-03
 9.49332595e-03 1.50258572e-02 3.37418661e-03 4.94317579e-03
 5.98488082e-03 4.54842076e-03 4.99141867e-03 1.65903978e-02
 4.91237317e-03 7.28885166e-03 6.36745621e-03 1.33917572e-02
 6.28356577e-03 7.13964429e-03 7.13821425e-03 1.59751652e-02
 6.41882998e-03 7.64721754e-03 1.62776158e-02 8.57654687e-03
 7.64721754e-03 8.98232287e-03 8.13687431e-03 7.89645803e-03
 8.90098531e-03 8.51964347e-03 8.08508990e-03 1.72643992e-02
 8.86948389e-03 9.22023607e-03 2.01086375e-02 2.13909906e-02
 1.05521284e-02 1.99249503e-02 1.03349188e-02 9.82126974e-03
 1.04846708e-02 3.22766724e-02 4.18291549e-02 1.12750179e-02
 1.09072460e-02 1.15831427e-02 1.14176787e-02 2.29934203e-02
 1.12501771e-02 1.20844660e-02 1.10766217e-02 1.17285929e-02
 1.13455801e-02 1.16161455e-02 1.18747446e-02 1.17746633e-02
 2.43627756e-02 1.30455569e-02 1.22276075e-02 1.23083739e-02
 1.35702072e-02 6.68355875e-02 2.64048707e-02 2.64227453e-02
 1.24333419e-02 1.27369322e-02 6.59676107e-02 1.24404248e-02
 5.50191332e-02 1.27837904e-02 1.36103441e-02 1.34238833e-02
 2.67718630e-02 1.36407694e-02 3.04637923e-02 1.38510787e-02
 1.67550858e-01 1.46863490e-02 1.49479000e-02 1.46724068e-02
 1.51344992e-02 3.01422477e-02 2.99871466e-02 2.96874341e-02
 8.16808649e-02 1.54008745e-02 3.19745942e-02 1.59666661e-02
 1.61138574e-02 1.61138574e-02 3.41042871e-02 1.61354292e-02
 3.39910789e-02 1.63132576e-02 3.56393971e-02 7.18675593e-02
 1.78924764e-02 1.74457237e-02 1.71389064e-02 1.04179133e-01
 1.97732182e-02 1.82007228e-02 2.02620792e-02 1.83663202e-02
 4.20396654e-02 7.50891528e-02 1.89194795e-02 1.88696852e-02
 1.91265005e-02 5.63168646e-02 1.92350761e-02 1.88206286e-02
 1.93473329e-02 1.92350761e-02 5.97170587e-02 3.92916929e-02
 3.99479240e-02 2.01148879e-02 2.02620792e-02 1.32024656e-01
 2.13165617e-02 1.40466044e-01 2.11158179e-02 2.34110073e-02
 6.81339249e-02 2.11158179e-02 2.17587186e-02 4.35174373e-02
 2.21339792e-02 2.27113083e-02 2.28728651e-02 2.27113083e-02
 4.64434820e-02 2.04083036e-01 2.30427105e-02 2.42992986e-02
 2.48524578e-02 2.40539080e-02 2.42992986e-02]
 
"20_newsgroups/sci.med/58763"
>>> print(t2_result2[t2_result2.nonzero()])
[2.34482371e-03 4.14265386e-03 4.42577019e-03 2.92148526e-03
 1.33936842e-03 2.16121698e-03 1.08191180e-02 8.05687963e-03
 2.58109075e-03 8.59275516e-03 4.17703243e-03 4.12642026e-03
 9.62545664e-03 4.20143956e-03 6.31741620e-03 5.31671210e-03
 1.48492077e-02 2.34245926e-05 6.75606643e-04 2.85621422e-03
 1.39301109e-02 7.98215533e-03 5.15843543e-03 7.88937191e-03
 8.61158132e-03 6.33508993e-03 9.41006605e-03 1.04688183e-02
 1.10776054e-02 1.06254158e-02 1.15837546e-02 1.47099141e-02
 1.39793137e-02 1.47149138e-02 1.53791960e-02 1.36221220e-02
 1.58114516e-02 3.46935867e-02 3.42222836e-02 1.70775536e-02
 1.82594869e-02 1.83374808e-02 2.12790916e-02 1.99693017e-02
 2.16014850e-02 2.17616535e-02 2.77570110e-02 2.30871061e-02
 2.31437988e-02 2.52717384e-02 2.50165686e-02 5.76677542e-02
 2.58076567e-02 2.72681028e-02 3.02984539e-02 2.82909350e-02
 6.64934520e-02 3.03504273e-02 3.12699320e-02 3.30500207e-02
 6.64437477e-02 4.11898951e-02 2.22132596e-01 3.43093815e-02
 3.48071684e-02 3.87869947e-02 3.79869411e-02 4.06113152e-02
 3.78096918e-02 3.85914817e-02 8.45144911e-02 4.43275669e-02
 8.94617535e-02 4.18132151e-02 4.35768377e-02 4.37580704e-02
 4.24887787e-02 4.41332318e-02 4.76963992e-02 4.50471728e-02
 5.07453196e-02 4.99174635e-02 1.62708477e-01 5.61201497e-02
 5.70171306e-02]

"20_newsgroups/talk.politics.mideast/75944" 
>>> print(t2_result3[t2_result3.nonzero()])
[5.55352983e-03 2.68909110e-03 7.40110061e-03 2.03408687e-03
 5.07281261e-03 1.94765684e-03 4.32357526e-03 2.42662960e-03
 2.46751814e-03 4.14623045e-03 1.63016258e-03 6.63300399e-03
 3.22437591e-03 2.43933714e-03 1.69913515e-03 1.15829341e-03
 1.93813085e-03 4.05282385e-03 3.94605275e-03 2.94837864e-03
 9.89166828e-04 4.43327453e-03 1.49241041e-03 5.29276880e-04
 1.04332327e-02 1.86305185e-03 1.49942496e-03 1.04204966e-03
 1.64383106e-06 2.22874243e-03 4.74109925e-05 1.23532438e-02
 1.00218043e-03 9.84284124e-04 9.66300028e-04 3.03943414e-03
 3.98711003e-03 2.13439679e-03 3.58058385e-03 1.57591393e-03
 2.18202654e-03 1.07565823e-03 5.40838415e-04 5.60151251e-04
 3.85212976e-03 1.44798188e-03 2.21456054e-03 6.24756043e-03
 5.63741566e-04 4.86629728e-03 4.91010175e-03 7.85617945e-03
 1.77827086e-03 2.30674444e-03 7.11302781e-03 1.97073566e-03
 2.16948762e-03 1.31183789e-03 1.37089207e-03 1.94384576e-03
 5.82585996e-03 2.87323282e-03 1.36422028e-03 1.45468436e-03
 3.48190313e-03 6.75875083e-03 2.96782542e-03 5.14257742e-03
 1.55475163e-03 1.39532678e-03 7.45326254e-04 1.49128643e-03
 8.20805276e-04 1.73490654e-03 1.60060259e-03 8.05093881e-04
 5.13518884e-03 2.51089601e-03 2.55926730e-03 2.43868517e-03
 8.69422642e-04 8.91140327e-04 1.51671865e-03 1.87627690e-03
 1.47342398e-03 3.73775236e-03 2.91489493e-03 8.96495531e-04
 2.75230472e-03 2.73904231e-03 3.95368533e-03 6.44012431e-03
 9.42311781e-04 2.15391969e-03 9.92003186e-04 2.99621868e-03
 2.01782550e-03 9.64430211e-04 4.04104243e-03 6.19364804e-03
 3.09787659e-03 1.14541918e-02 1.04846302e-03 6.47545097e-03
 2.95071971e-03 8.39579341e-04 3.03230064e-03 1.24702611e-03
 2.07795685e-03 1.04594217e-03 1.06979368e-03 9.55938385e-04
 3.67029533e-03 3.47936240e-03 2.19291998e-03 5.47151658e-03
 2.17653851e-03 2.28880061e-03 2.18236186e-03 2.14786289e-03
 1.21731883e-03 1.35951071e-03 1.14977073e-03 1.20600224e-03
 1.23711730e-03 3.66000119e-03 1.48462325e-03 1.19257474e-03
 1.72313102e-03 1.19607752e-03 4.10500158e-03 3.68883442e-03
 5.06103328e-03 1.23485508e-03 1.23260187e-03 6.43420381e-03
 1.26314466e-03 1.23110470e-03 2.78202602e-03 8.51899638e-03
 2.67547109e-03 2.57533267e-03 1.30813573e-03 1.32759742e-03
 1.36801637e-03 1.33264378e-03 1.39333172e-03 1.34348109e-03
 4.07197873e-03 6.66769503e-03 1.33353901e-03 1.35670366e-03
 1.47918903e-03 1.40202823e-03 2.74751734e-03 1.77540794e-03
 1.40949266e-03 1.49924148e-03 9.18558222e-03 1.79396471e-03
 1.55338061e-03 2.81081790e-03 1.41636501e-03 4.56383287e-03
 2.84734386e-03 1.47113430e-03 1.52461646e-03 4.36830616e-03
 2.95067829e-03 3.09275502e-03 4.57133971e-03 1.48167704e-02
 1.48462325e-03 1.51589368e-03 1.65700261e-03 1.48775211e-03
 3.03591674e-03 4.51704519e-03 1.53946001e-03 3.31189157e-03
 9.83272301e-03 1.65489093e-03 1.64496664e-03 3.16458638e-03
 1.45240556e-03 2.28303210e-02 6.29239334e-03 1.58554701e-03
 1.56091760e-03 1.66071713e-03 1.99968113e-03 1.66606623e-03
 5.27421702e-03 1.60643945e-03 1.63776379e-03 3.36263684e-03
 3.65595877e-03 1.64912409e-03 1.80347638e-03 3.48865882e-03
 1.66660393e-03 1.94345627e-03 1.70442085e-03 1.62412623e-03
 1.68076656e-03 5.49686557e-03 1.63166204e-03 3.52248566e-03
 7.19752145e-03 6.83598735e-02 1.83881439e-03 1.84320715e-03
 7.46690323e-03 3.46786769e-03 3.56657291e-03 1.92702625e-03
 5.32036598e-03 1.76571157e-03 1.79938036e-03 1.80416194e-03
 1.76187906e-03 1.85734685e-03 1.71545526e-03 1.81315065e-03
 1.86112730e-03 3.59468683e-03 1.59756893e-02 1.82016352e-03
 1.77086228e-03 1.74309645e-03 1.21224377e-02 2.00065102e-03
 1.81734793e-03 1.91772770e-03 7.21116660e-03 3.93348304e-03
 2.03259917e-03 2.05887738e-03 2.34546450e-03 1.89553149e-03
 7.72521564e-03 1.92193539e-03 2.03672255e-03 1.84394260e-03
 1.93474947e-03 1.94697684e-03 1.94433436e-03 1.83156805e-03
 1.91521803e-03 5.49038956e-03 8.21409286e-03 8.01818917e-03
 8.14275553e-03 5.96451082e-03 2.11184886e-03 6.05219603e-03
 1.90775509e-03 1.92362726e-03 2.01540245e-03 2.04401155e-03
 1.92447510e-03 2.20403189e-03 8.25713073e-03 2.01839944e-03
 1.98912062e-03 2.15097846e-03 2.10247505e-03 2.06864441e-03
 2.00847057e-03 2.01341323e-03 2.01839944e-03 2.01639968e-03
 2.01242124e-03 1.96128234e-03 2.11898254e-03 3.98396254e-03
 1.99774632e-03 2.15991104e-03 5.10952554e-03 2.13969708e-03
 2.09199310e-02 2.24287849e-03 2.11303158e-03 5.25845180e-03
 2.36916233e-03 2.05352321e-03 2.06755082e-03 1.11048437e-02
 2.07858296e-03 2.01440697e-03 4.13728881e-03 2.03054869e-03
 2.46201356e-03 4.93283542e-03 2.30749147e-03 2.10363832e-03
 2.10714255e-03 2.13475442e-03 1.39157982e-02 2.04191938e-03
 2.20403189e-03 2.10831547e-03 2.21243696e-03 2.50530503e-03
 6.34621339e-03 2.38425472e-03 4.51594175e-03 2.33485298e-03
 2.31420883e-03 2.26722336e-03 4.35376743e-03 2.14093951e-03
 4.70530204e-03 2.40486621e-02 2.26722336e-03 2.59769755e-03
 2.36360486e-03 4.91528683e-03 2.35810144e-03 2.08193498e-03
 4.44193749e-03 4.36978462e-03 4.39975142e-03 4.42487393e-03
 2.27190695e-03 2.34725259e-03 9.25008802e-03 2.19438119e-03
 2.32443678e-03 2.35265102e-03 4.53756051e-03 2.21953782e-03
 2.41976029e-03 2.23254830e-03 2.25340075e-03 2.55877551e-02
 4.77618311e-03 2.31929970e-03 2.37665822e-03 2.23548059e-03
 2.22384150e-03 2.40568668e-03 2.41368584e-03 2.29592460e-03
 4.66970596e-03 2.30250527e-03 2.35265102e-03 2.24736409e-03
 2.37477492e-03 2.77652816e-03 2.29756261e-03 5.41634831e-03
 2.25053002e-02 2.41167542e-03 4.71985995e-03 1.66764221e-02
 7.06338600e-03 7.24711025e-03 5.10436898e-03 2.62336128e-03
 2.33660781e-03 4.73460754e-03 2.30749147e-03 2.47085641e-03
 2.55995483e-03 5.02971367e-03 2.47533019e-03 5.01535582e-03
 2.38234601e-03 2.46641771e-03 7.50176674e-03 2.17751549e-02
 2.57851161e-03 2.37289786e-03 2.53197052e-03 2.53445813e-03
 2.46201356e-03 2.17474640e-02 2.69147881e-03 2.37477492e-03
 2.64415898e-03 5.00117782e-03 2.49591177e-03 2.39976065e-03
 2.43003155e-03 2.46641771e-03 2.35627879e-03 2.62336128e-03
 2.53946641e-03 2.42384645e-03 2.74311926e-03 2.61467675e-03
 2.70143680e-03 2.64114068e-02 2.43628499e-03 2.61467675e-03
 2.53445813e-03 5.13038994e-03 2.51969388e-03 4.95066039e-03
 8.19722195e-03 1.16381745e-02 2.53197052e-03 2.56256884e-03
 2.63218116e-03 2.65639581e-03 2.60049227e-03 2.51969388e-03
 2.55218449e-03 9.55292262e-03 2.55476277e-03 2.67207357e-03
 2.54706291e-03 2.68819805e-03 2.56256884e-03 2.88124119e-03
 2.19162083e-02 2.76517131e-03 2.71843300e-03 2.70479545e-03
 2.92424397e-03 2.60330087e-03 2.58392726e-03 2.72888125e-03
 1.73151664e-02 2.81611990e-03 2.68819805e-03 2.67526192e-03
 2.84558020e-03 2.78811760e-03 2.77652816e-03 2.65331171e-03
 2.93933636e-03 6.09117030e-03 2.74311926e-03 2.83700533e-03
 2.76143578e-03 2.75037489e-03 2.75403788e-03 2.86760364e-03
 3.33675554e-02 5.73520728e-03 2.76143578e-03 2.70143680e-03
 2.89995136e-03 2.70817415e-03 2.74673545e-03 5.55305633e-03
 2.78036500e-03 2.81203373e-03 8.30679499e-03 8.83337381e-03
 3.05177025e-03 2.96542074e-03 2.79597788e-03 3.12468076e-03
 2.99839692e-03 2.79994934e-03 2.78036500e-03 2.83700533e-03
 2.83276612e-03 6.16750452e-03 2.81611990e-03 2.89521551e-03
 2.83700533e-03 8.61633923e-03 2.76517131e-03 2.81611990e-03
 2.91440144e-03 2.83276612e-03 2.77271717e-03 2.81611990e-03
 2.81611990e-03 3.17650147e-03 2.83276612e-03 2.98166868e-03
 6.33760322e-03 3.05802370e-03 2.96542074e-03 1.22070810e-02
 5.97438000e-03 9.27111424e-03 3.13179948e-03 3.09037141e-03
 2.93933636e-03 1.22320948e-02 2.94445794e-03 2.95484228e-03
 1.31125380e-02 3.37946345e-03 2.92923018e-03 3.17650147e-03
 6.55626902e-03 1.36084148e-02 3.16880161e-03 3.00983026e-03
 3.02742538e-03 3.14631133e-03 6.11604739e-03 9.19304104e-03
 3.08375226e-03 3.06434701e-03 3.08375226e-03 6.27801779e-03
 3.03341413e-03 3.03946692e-03 6.11604739e-03 3.22503957e-03
 3.10384660e-03 3.15370923e-03 3.21665526e-03 3.20839334e-03
 3.18430754e-03 3.11070645e-03 3.20839334e-03 3.15370923e-03
 6.32241022e-03 3.16880161e-03 3.34711573e-03 3.12468076e-03
 3.22503957e-03 3.17650147e-03 6.43331051e-03 3.15370923e-03
 6.36861508e-03 3.17650147e-03 6.40050062e-03 6.48438061e-03
 3.32653415e-03 3.17650147e-03 3.18430754e-03 3.25096461e-03
 3.21665526e-03 1.39041028e-02 3.23354997e-03 3.33673138e-03
 3.46301523e-03 3.43785860e-03 3.10529263e-02 7.43761520e-03
 3.30667489e-03 3.25987709e-03 3.50297990e-03 3.37946345e-03
 6.69423146e-03 1.16448474e-02 3.39067037e-03 3.31651742e-03
 3.36847415e-03 3.32653415e-03 3.42568757e-03 1.03890457e-02
 3.32653415e-03 3.41377280e-03 3.34711573e-03 3.36847415e-03
 3.71880760e-03 1.39041028e-02 3.54598267e-03 3.47602571e-03
 3.42568757e-03 1.03890457e-02 7.21785740e-03 3.51695421e-03
 3.41377280e-03 3.45029714e-03 7.06256468e-03 3.46301523e-03
 3.53128234e-03 3.47602571e-03 3.54598267e-03 3.56107506e-03
 7.12215012e-03 3.53128234e-03 3.51695421e-03 3.76074760e-03
 3.57658099e-03 3.60892870e-03 3.71880760e-03 4.36112788e-03
 3.71880760e-03 3.83013205e-03 7.52149519e-03 3.67976240e-03
 3.73938918e-03 3.78294381e-03 3.73938918e-03 3.78294381e-03
 3.71880760e-03 3.78294381e-03 3.88161579e-03 3.83013205e-03
 3.90922766e-03 3.83013205e-03 3.90922766e-03 8.00240430e-03
 3.93825612e-03 4.15302104e-03 4.11108105e-03 4.11108105e-03
 4.03551150e-03 1.67932788e-02 8.72225576e-03 1.32833548e-02
 8.39663938e-03 4.11108105e-03 4.30150110e-03 4.82005839e-03]
```

### Task 3

**Code**

```python
################################## TASK 3 #####################################

def predictLabel(k, str):
	# parse the input string into a list of words
	article = regex.sub(' ', str).lower().split()
	listOfWords = np.array(article)
	
	# create new 20,000 entry count vector for this article
	countVector = np.zeros(20000)
	for wd in listOfWords:
		# get the rank of the word and increment it in the countVector
		rank = wordRank.lookup(wd)
		countVector[rank] += 1
	
	# create the TF x IDF vector for this article
	tfIDF = (countVector / countVector.sum()) * idf
	
	# calculate the l2 norm between the corpus and the given article
	l2Norm = task2Result.map(lambda x: (x[0], ((x[1] - tfIDF) * (x[1] - tfIDF)).sum()))
	# get the k closest documents to the given article
	kNearest = l2Norm.top(k, lambda x: -x[1])
	
	# remove the "20_newsgroups/" part of the name
	kNearest2 = list(map(lambda x: (x[0][14:], x[1]), kNearest))
	# remove the "/1231234" part of the name
	kNearest3 = list(map(lambda x: (x[0][:x[0].index("/")], x[1]), kNearest2))
	# remove the value from the tuple 
	kNearest4 = list(map(lambda x: x[0], kNearest3))
	
	# find the most frequent document class
	best = defaultdict(int)
	for doc in kNearest4:
		best[doc] += 1
	print best

	# get the number of labels that there are most of to check for ties
	maxNumDocs = max(list(best.values()))

	return keyWithMaxVal(best)

# get the key from the given dictionary that has the highest value
def keyWithMaxVal(d):
    v = list(d.values())
    k = list(d.keys())
    return k[v.index(max(v))]

# predict the news group for each of the following wikipedia articles
t3r1 = predictLabel (10, 'Graphics are pictures and movies created using computers – usually referring to image data created by a computer specifically with help from specialized graphical hardware and software. It is a vast and recent area in computer science. The phrase was coined by computer graphics researchers Verne Hudson and William Fetter of Boeing in 1960. It is often abbreviated as CG, though sometimes erroneously referred to as CGI. Important topics in computer graphics include user interface design, sprite graphics, vector graphics, 3D modeling, shaders, GPU design, implicit surface visualization with ray tracing, and computer vision, among others. The overall methodology depends heavily on the underlying sciences of geometry, optics, and physics. Computer graphics is responsible for displaying art and image data effectively and meaningfully to the user, and processing image data received from the physical world. The interaction and understanding of computers and interpretation of data has been made easier because of computer graphics. Computer graphic development has had a significant impact on many types of media and has revolutionized animation, movies, advertising, video games, and graphic design generally.')
t3r2 = predictLabel (10, 'A deity is a concept conceived in diverse ways in various cultures, typically as a natural or supernatural being considered divine or sacred. Monotheistic religions accept only one Deity (predominantly referred to as God), polytheistic religions accept and worship multiple deities, henotheistic religions accept one supreme deity without denying other deities considering them as equivalent aspects of the same divine principle, while several non-theistic religions deny any supreme eternal creator deity but accept a pantheon of deities which live, die and are reborn just like any other being. A male deity is a god, while a female deity is a goddess. The Oxford reference defines deity as a god or goddess (in a polytheistic religion), or anything revered as divine. C. Scott Littleton defines a deity as a being with powers greater than those of ordinary humans, but who interacts with humans, positively or negatively, in ways that carry humans to new levels of consciousness beyond the grounded preoccupations of ordinary life.') 
t3r3 = predictLabel (10, 'Egypt, officially the Arab Republic of Egypt, is a transcontinental country spanning the northeast corner of Africa and southwest corner of Asia by a land bridge formed by the Sinai Peninsula. Egypt is a Mediterranean country bordered by the Gaza Strip and Israel to the northeast, the Gulf of Aqaba to the east, the Red Sea to the east and south, Sudan to the south, and Libya to the west. Across the Gulf of Aqaba lies Jordan, and across from the Sinai Peninsula lies Saudi Arabia, although Jordan and Saudi Arabia do not share a land border with Egypt. It is the worlds only contiguous Eurafrasian nation. Egypt has among the longest histories of any modern country, emerging as one of the worlds first nation states in the tenth millennium BC. Considered a cradle of civilisation, Ancient Egypt experienced some of the earliest developments of writing, agriculture, urbanisation, organised religion and central government. Iconic monuments such as the Giza Necropolis and its Great Sphinx, as well the ruins of Memphis, Thebes, Karnak, and the Valley of the Kings, reflect this legacy and remain a significant focus of archaeological study and popular interest worldwide. Egypts rich cultural heritage is an integral part of its national identity, which has endured, and at times assimilated, various foreign influences, including Greek, Persian, Roman, Arab, Ottoman, and European. One of the earliest centers of Christianity, Egypt was Islamised in the seventh century and remains a predominantly Muslim country, albeit with a significant Christian minority.')
t3r4 = predictLabel (10, 'The term atheism originated from the Greek atheos, meaning without god(s), used as a pejorative term applied to those thought to reject the gods worshiped by the larger society. With the spread of freethought, skeptical inquiry, and subsequent increase in criticism of religion, application of the term narrowed in scope. The first individuals to identify themselves using the word atheist lived in the 18th century during the Age of Enlightenment. The French Revolution, noted for its unprecedented atheism, witnessed the first major political movement in history to advocate for the supremacy of human reason. Arguments for atheism range from the philosophical to social and historical approaches. Rationales for not believing in deities include arguments that there is a lack of empirical evidence; the problem of evil; the argument from inconsistent revelations; the rejection of concepts that cannot be falsified; and the argument from nonbelief. Although some atheists have adopted secular philosophies (eg. humanism and skepticism), there is no one ideology or set of behaviors to which all atheists adhere.')
t3r5 = predictLabel (10, 'President Dwight D. Eisenhower established NASA in 1958 with a distinctly civilian (rather than military) orientation encouraging peaceful applications in space science. The National Aeronautics and Space Act was passed on July 29, 1958, disestablishing NASAs predecessor, the National Advisory Committee for Aeronautics (NACA). The new agency became operational on October 1, 1958. Since that time, most US space exploration efforts have been led by NASA, including the Apollo moon-landing missions, the Skylab space station, and later the Space Shuttle. Currently, NASA is supporting the International Space Station and is overseeing the development of the Orion Multi-Purpose Crew Vehicle, the Space Launch System and Commercial Crew vehicles. The agency is also responsible for the Launch Services Program (LSP) which provides oversight of launch operations and countdown management for unmanned NASA launches.')
t3r6 = predictLabel (10, 'The transistor is the fundamental building block of modern electronic devices, and is ubiquitous in modern electronic systems. First conceived by Julius Lilienfeld in 1926 and practically implemented in 1947 by American physicists John Bardeen, Walter Brattain, and William Shockley, the transistor revolutionized the field of electronics, and paved the way for smaller and cheaper radios, calculators, and computers, among other things. The transistor is on the list of IEEE milestones in electronics, and Bardeen, Brattain, and Shockley shared the 1956 Nobel Prize in Physics for their achievement.')
t3r7 = predictLabel (10, 'The Colt Single Action Army which is also known as the Single Action Army, SAA, Model P, Peacemaker, M1873, and Colt .45 is a single-action revolver with a revolving cylinder holding six metallic cartridges. It was designed for the U.S. government service revolver trials of 1872 by Colts Patent Firearms Manufacturing Company – todays Colts Manufacturing Company – and was adopted as the standard military service revolver until 1892. The Colt SAA has been offered in over 30 different calibers and various barrel lengths. Its overall appearance has remained consistent since 1873. Colt has discontinued its production twice, but brought it back due to popular demand. The revolver was popular with ranchers, lawmen, and outlaws alike, but as of the early 21st century, models are mostly bought by collectors and re-enactors. Its design has influenced the production of numerous other models from other companies.')
t3r8 = predictLabel (10, 'Howe was recruited by the Red Wings and made his NHL debut in 1946. He led the league in scoring each year from 1950 to 1954, then again in 1957 and 1963. He ranked among the top ten in league scoring for 21 consecutive years and set a league record for points in a season (95) in 1953. He won the Stanley Cup with the Red Wings four times, won six Hart Trophies as the leagues most valuable player, and won six Art Ross Trophies as the leading scorer. Howe retired in 1971 and was inducted into the Hockey Hall of Fame the next year. However, he came back two years later to join his sons Mark and Marty on the Houston Aeros of the WHA. Although in his mid-40s, he scored over 100 points twice in six years. He made a brief return to the NHL in 1979–80, playing one season with the Hartford Whalers, then retired at the age of 52. His involvement with the WHA was central to their brief pre-NHL merger success and forced the NHL to expand their recruitment to European talent and to expand to new markets.')

# print results
print(t3r1)
print(t3r2)
print(t3r3)
print(t3r4)
print(t3r5)
print(t3r6)
print(t3r7)
print(t3r8)
```

**Results**

```
>>> print(t3r1)
comp.graphics

>>> print(t3r2)
talk.religion.misc

>>> print(t3r3)
alt.atheism

>>> print(t3r4)
alt.atheism

>>> print(t3r5)
sci.space

>>> print(t3r6)
talk.politics.misc

>>> print(t3r7)
talk.politics.guns

>>> print(t3r8)
talk.politics.mideast
```

